{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics and Scoring\n",
        "\n",
        "We will use the widely popular sklearn library to demonstrate how evaluation metrics work.  It should be noted that there are multiple ways to perform evaluation in sklearn.  First, each ML algorithm implemented in sklearn comes with its own evaluation method \"out of the box\".  This will be demonstrated down the road in the course, when we use these algoriths.\n",
        "The second, which is featured in this notebook, is by using sklearn.metrics.\n",
        "\n",
        "For a complete reference, refer to:\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics"
      ],
      "metadata": {
        "id": "FTB5p-ewT1iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "v1D4bae4eSd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Evaluation Metrics"
      ],
      "metadata": {
        "id": "7Vr7rnyXUC6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a small toy dataset containing labels (y) and predictions\n",
        "# (y_hat) only.  We will not be needing features here.\n",
        "# The data here will be stored in numpy arrays, although generally\n",
        "# you can apply the sklearn evaluation metrics on pandas Series (columns of\n",
        "# dataframes) or even python lists.\n",
        "y = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y_hat = np.array([1.0, 2.5, 2.7, 5.0, 5.5])\n"
      ],
      "metadata": {
        "id": "GMITc5JmT55J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y, y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwQ0OiemLhh8",
        "outputId": "8efd720b-1660-4887-e335-cc4ab19c69f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31799999999999995"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that you get the same as below:\n",
        "MSE = np.mean(np.square(y-y_hat))\n",
        "MSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK7VCvt7MFmN",
        "outputId": "3d64ec81-1d7f-41d8-f8c5-2e1465c264f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31799999999999995"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "MAE = mean_absolute_error(y, y_hat)\n",
        "MAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUyV_cNKMQRL",
        "outputId": "bd20f690-201f-4d54-c0c5-afeb225e3f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "np.mean(np.abs(y-y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhjlxCQ_MdX_",
        "outputId": "7cab9483-bd86-4513-dbe7-f0293cfd4a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "MAPE = mean_absolute_percentage_error(y, y_hat)\n",
        "MAPE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm1r6cOxohjr",
        "outputId": "233674a0-63f9-4c41-eb08-1e3c29e2a42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "np.mean(np.abs(y - y_hat)/np.abs(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d1qynqZouN2",
        "outputId": "401d132a-250a-48c3-8805-c2e649ba8d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13999999999999996"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(y, y_hat)"
      ],
      "metadata": {
        "id": "xAdNR1pOMfK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify it's the same\n",
        "1 - MSE / np.var(y)"
      ],
      "metadata": {
        "id": "D2LiIM81QSzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification - Hard Prediction"
      ],
      "metadata": {
        "id": "JiBUtYHuSROb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1])\n",
        "y_hat = np.array([1,1,1,-1,1,1,-1,-1,1,-1,-1,-1,-1,-1,-1,-1])\n"
      ],
      "metadata": {
        "id": "HijNO_0-QulK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y, y_hat)"
      ],
      "metadata": {
        "id": "Y3Ct7HulSkG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that it is the same as below.\n",
        "# \"y==y_hat\" is an array of True/False, with \"True\" at indices where the two\n",
        "# arrays are equal, and  False otherwise.  The \"np.sum\" of that is the number\n",
        "# of \"True\"s, beacuse when you sum up booleans, the Trues are interpreted as 1's\n",
        "# and the Falses are 0's.\n",
        "np.sum(y == y_hat)/len(y)"
      ],
      "metadata": {
        "id": "MIBGovEoSp8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rate\n",
        "from sklearn.metrics import zero_one_loss\n",
        "zero_one_loss(y, y_hat)"
      ],
      "metadata": {
        "id": "n3w2AYWvSra6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "np.sum(y != y_hat)/len(y)"
      ],
      "metadata": {
        "id": "oTuUiKdrSt33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf = confusion_matrix(y, y_hat)\n",
        "conf"
      ],
      "metadata": {
        "id": "F666aR1eVuCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that it is the same\n",
        "TN, FP, FN, TP = \\\n",
        "    np.sum((y==-1)*(y_hat==-1)), np.sum((y==-1)*(y_hat==1)), \\\n",
        "    np.sum((y==1)*(y_hat==-1)), np.sum((y==1)*(y_hat==1))\n",
        "np.array([[TN, FP],\n",
        "          [FN, TP]])"
      ],
      "metadata": {
        "id": "s7GmNYvtV0x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision = precision_score(y, y_hat)\n",
        "precision"
      ],
      "metadata": {
        "id": "lkudJrnbTS4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "TP/(TP+FP)"
      ],
      "metadata": {
        "id": "nVmtP47pTqNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall = recall_score(y, y_hat)\n",
        "recall"
      ],
      "metadata": {
        "id": "SRSnQHW7T8F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "TP/(TP+FN)"
      ],
      "metadata": {
        "id": "roe5M5JOUJgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y, y_hat)"
      ],
      "metadata": {
        "id": "5vJLpGSrVQsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it's the same\n",
        "2 * precision * recall / (precision + recall)"
      ],
      "metadata": {
        "id": "sBnR2YiMVeQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification - Soft Prediction"
      ],
      "metadata": {
        "id": "46tOa-pVXJhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label: -1 or +1\n",
        "# prediction: probability of +1\n",
        "y = np.array([1,1,1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1])\n",
        "y_hat = np.array([0.9,0.95,0.7,0.2,0.1,0.051,0.06,0.8,0.89,0.49,0.4,0.45,0.61,0.3,0.35,0.36])"
      ],
      "metadata": {
        "id": "Ko7XYMU_VhEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert soft prediction to hard prediction using threshold\n",
        "thresh = 0.6\n",
        "y_hat_hard = np.where(y_hat > thresh, 1, -1)\n",
        "y_hat_hard"
      ],
      "metadata": {
        "id": "hMyBQyPTXXkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-entropy loss\n",
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "tJU2HRerX6iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn's log_loss expects 0/1 labels (instead of -1, +1).  (y+1)/2 converts.\n",
        "log_loss(((y+1)/2), y_hat)"
      ],
      "metadata": {
        "id": "u0XVBbaPYQO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that it's the same\n",
        "np.mean(-(1+y)/2 * np.log(y_hat) - (1-y)/2 * np.log(1-y_hat))"
      ],
      "metadata": {
        "id": "VkeHk-L7YbBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "# ROC curve = FPR vs TPR\n",
        "FPR, TPR, _ = roc_curve(y, y_hat)"
      ],
      "metadata": {
        "id": "oEj-o1lSYo8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(FPR, TPR)"
      ],
      "metadata": {
        "id": "dltvhPk_Zg9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y, y_hat)"
      ],
      "metadata": {
        "id": "3EiqljBtaFW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that it equals equivalent definition of auc\n",
        "\n",
        "negative_indices = np.where(y==-1)[0]\n",
        "positive_indices = np.where(y==1)[0]\n",
        "\n",
        "# number of (negative,positive) pairs for which y_hat is ordered correctly\n",
        "num_pairs_ordered_correctly = np.sum(\n",
        "    [[y_hat[j] > y_hat[k]\n",
        "      for k in negative_indices]\n",
        "        for j in positive_indices])\n",
        "\n",
        "# number of (negative, positve) pairs\n",
        "num_pairs = len(negative_indices) * len(positive_indices)\n",
        "\n",
        "# AUC = ratio of last two expressions\n",
        "num_pairs_ordered_correctly / num_pairs"
      ],
      "metadata": {
        "id": "oclNPyO3aQxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSBkSC8Hzuac"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}